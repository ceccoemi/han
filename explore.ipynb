{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from dataset import SentWordDataset\n",
    "from config import BATCH_SIZE, WORD_HIDDEN_SIZE, SENT_HIDDEN_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEncoder(nn.Module):\n",
    "    def __init__(self, embedding_matrix, hidden_size):\n",
    "        super(WordEncoder, self).__init__()\n",
    "        embedding_dim = embedding_matrix.shape[1]\n",
    "        self.embedding = nn.Embedding.from_pretrained(\n",
    "            embeddings=torch.FloatTensor(embedding_matrix), freeze=True,\n",
    "        )\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=embedding_dim, hidden_size=hidden_size, bidirectional=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, input, hidden_state):\n",
    "        output = self.embedding(input)\n",
    "        f_output, h_output = self.gru(output, hidden_state)\n",
    "        return f_output, h_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentEncoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(SentEncoder, self).__init__()\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=input_size, hidden_size=hidden_size, bidirectional=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, input, hidden_state):\n",
    "        f_output, h_output = self.gru(input, hidden_state)\n",
    "        return f_output, h_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.fc = nn.Linear(self.input_size, self.input_size)\n",
    "        self.context_vector = nn.Parameter(torch.randn(self.input_size))\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = torch.tanh(self.fc(input))\n",
    "        output = torch.matmul(output, self.context_vector)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        output = output.permute(1, 0)\n",
    "        input = input.permute(1, 0, 2)\n",
    "        batch_size = input.shape[1]\n",
    "        weighted_sum = torch.zeros(batch_size, self.input_size)\n",
    "        for alpha, h in zip(output, input):\n",
    "            alpha = alpha.unsqueeze(1).expand_as(h)\n",
    "            weighted_sum += alpha * h\n",
    "        return weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Han(nn.Module):\n",
    "    def __init__(self, embedding_matrix, word_hidden_size, sent_hidden_size, num_classes, batch_size):\n",
    "        super(Han, self).__init__()\n",
    "        self.word_encoder = WordEncoder(embedding_matrix, word_hidden_size)\n",
    "        self.word_attention = Attention(word_hidden_size * 2)\n",
    "        self.sent_encoder = SentEncoder(word_hidden_size * 2, sent_hidden_size)\n",
    "        self.sent_attention = Attention(sent_hidden_size * 2)\n",
    "        self.fc = nn.Linear(sent_hidden_size * 2, num_classes)\n",
    "        self.word_hidden_state = torch.zeros(2, batch_size, word_hidden_size)\n",
    "        self.sent_hidden_state = torch.zeros(2, batch_size, sent_hidden_size)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input = input.permute(1, 2, 0)\n",
    "        nn.init.zeros_(self.sent_hidden_state)\n",
    "        sent_encoder_outputs = []\n",
    "        for sentence in input:\n",
    "            nn.init.zeros_(self.word_hidden_state)\n",
    "            word_encoder_outputs = []\n",
    "            for word in sentence:\n",
    "                # Add an empty dimension because the GRU needs a 3D input,\n",
    "                # moreover this is the dimension where all the encoder\n",
    "                # outputs will be concatenated\n",
    "                word = word.unsqueeze(0)\n",
    "                output, word_hidden_state = self.word_encoder(word, self.word_hidden_state)\n",
    "                word_encoder_outputs.append(output)\n",
    "            word_attn_input = torch.cat(word_encoder_outputs, dim=0)\n",
    "            word_attn_input = word_attn_input.permute(1, 0, 2)\n",
    "            output = self.word_attention(word_attn_input)\n",
    "            # Add an empty dimension (as before)\n",
    "            output = output.unsqueeze(0)\n",
    "            output, sent_hidden_state = self.sent_encoder(output, self.sent_hidden_state)\n",
    "            sent_encoder_outputs.append(output)\n",
    "        sent_attn_input = torch.cat(sent_encoder_outputs, dim=0)\n",
    "        sent_attn_input = sent_attn_input.permute(1, 0, 2)\n",
    "        output = self.sent_attention(sent_attn_input)\n",
    "        output = self.fc(output)\n",
    "        output = F.log_softmax(output, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = KeyedVectors.load(\"embedding/yelp.wv\")\n",
    "df = pd.read_csv(\"data/yelp_train_sample.csv\").fillna(\"\")\n",
    "dataset = SentWordDataset(df.text, df.label, wv.vocab)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "model = Han(wv.vectors, WORD_HIDDEN_SIZE, SENT_HIDDEN_SIZE, 5, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5154, -1.6213, -1.6352, -1.6340, -1.6473],\n",
       "        [-1.5101, -1.6382, -1.6389, -1.6329, -1.6336],\n",
       "        [-1.5246, -1.6430, -1.6746, -1.6095, -1.6018]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter_loader = iter(loader)\n",
    "labels, features = next(iter_loader)\n",
    "predictions = model(features)\n",
    "predictions\n",
    "#features = features.permute(1, 2, 0)\n",
    "#sent_hidden_state = torch.zeros(2, BATCH_SIZE, SENT_HIDDEN_SIZE)\n",
    "#sent_encoder_outputs = []\n",
    "#for sentence in features:\n",
    "#    word_hidden_state = torch.zeros(2, BATCH_SIZE, WORD_HIDDEN_SIZE)\n",
    "#    word_encoder_outputs = []\n",
    "#    for word in sentence:\n",
    "#        # Add an empty dimension because the GRU needs a 3D input,\n",
    "#        # moreover this is the dimension where all the encoder\n",
    "#        # outputs will be concatenated\n",
    "#        word = word.unsqueeze(0)\n",
    "#        output, word_hidden_state = word_encoder(word, word_hidden_state)\n",
    "#        word_encoder_outputs.append(output)\n",
    "#    word_attn_input = torch.cat(word_encoder_outputs, dim=0)\n",
    "#    word_attn_input = word_attn_input.permute(1, 0, 2)\n",
    "#    output = word_attention(word_attn_input)\n",
    "#    # Add an empty dimension (as before)\n",
    "#    output = output.unsqueeze(0)\n",
    "#    output, sent_hidden_state = sent_encoder(output, sent_hidden_state)\n",
    "#    sent_encoder_outputs.append(output)\n",
    "#sent_attn_input = torch.cat(sent_encoder_outputs, dim=0)\n",
    "#sent_attn_input = sent_attn_input.permute(1, 0, 2)\n",
    "#output = sent_attention(sent_attn_input)\n",
    "#print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.7711e+00,  5.5403e-01, -2.7802e-01],\n",
       "         [ 9.7187e-01, -3.8668e-01, -9.7937e-01],\n",
       "         [ 1.1483e+00,  1.4296e+00, -7.4583e-01],\n",
       "         [ 1.8697e+00,  6.9198e-01, -1.0255e-01]],\n",
       "\n",
       "        [[-2.5148e+00, -2.5694e-01, -7.5848e-01],\n",
       "         [ 1.9415e+00,  9.1977e-01,  3.5009e-01],\n",
       "         [-5.3225e-01, -1.0782e+00, -1.1308e+00],\n",
       "         [ 9.1710e-01,  1.0315e-01, -1.0322e-01]],\n",
       "\n",
       "        [[-1.9805e-03, -2.3041e-01,  2.1059e-01],\n",
       "         [-1.4332e+00, -1.6309e+00, -3.9389e-01],\n",
       "         [-1.8161e-01,  2.1778e-01,  1.2066e-01],\n",
       "         [ 7.7609e-01,  4.9084e-01, -7.2770e-01]],\n",
       "\n",
       "        [[-2.0876e-01,  9.7782e-01,  1.9496e+00],\n",
       "         [ 1.4178e-01,  7.9491e-01, -5.2412e-01],\n",
       "         [-7.2215e-01, -4.0194e-01,  9.1482e-01],\n",
       "         [-1.3133e+00, -1.5092e+00,  1.1074e+00]],\n",
       "\n",
       "        [[-2.2761e-01,  3.8097e-01,  4.7954e-01],\n",
       "         [-1.0804e+00,  4.4056e-01,  6.7093e-01],\n",
       "         [-3.2950e-01,  8.9058e-01, -4.0156e-01],\n",
       "         [ 1.1965e+00, -6.1624e-01, -1.9006e+00]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn(5,4,3)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(t.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, b in zip(t, h):\n",
    "    a = a.unsqueeze(1).expand_as(b)\n",
    "    print(a.shape)\n",
    "    print(b.shape)\n",
    "    print((a * b).shape)\n",
    "    print((a * b))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
